{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lower,desc, mean, explode, lit, dayofmonth, to_date, cast\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "\n",
    "# SI TRABAJAMOS EN EL CLUSTER DE LA UNI NECESITAREMOS LA SIGUIENTE LINEA:\n",
    "# spark.conf.set(\"spark.sql.legacy.timeParserPolicy\",\"LEGACY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+\n",
      "|       Fases| count|\n",
      "+------------+------+\n",
      "|Pre Covid-19|804063|\n",
      "+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multasD19 = spark.read.csv('Multas/201912_detalle.csv', header=True, inferSchema=True, sep=\";\").na.drop()\n",
    "multasE20 = spark.read.csv('Multas/202001_detalle.csv', header=True, inferSchema=True, sep=\";\").na.drop()\n",
    "multasF20 = spark.read.csv('Multas/202002_detalle.csv', header=True, inferSchema=True, sep=\";\").na.drop()\n",
    "multasM20 = spark.read.csv('Multas/202003_detalle.csv', header=True, inferSchema=True, sep=\";\").na.drop()\n",
    "\n",
    "unionFase1 = multasD19.union(multasE20).union(multasF20).union(multasM20)\n",
    "intFase1 = unionFase1.withColumn(\"Fases\", lit('Pre Covid-19'))\n",
    "\n",
    "intFase1 = intFase1.groupBy(\"Fases\").count()\n",
    "intFase1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+\n",
      "|        Fases| count|\n",
      "+-------------+------+\n",
      "|Primer estado|487713|\n",
      "+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multasA20 = spark.read.csv('Multas/202004_detalle.csv', header=True, inferSchema=True, sep=\";\").na.drop()\n",
    "multasMa20 = spark.read.csv('Multas/202005_detalle.csv', header=True, inferSchema=True, sep=\";\").na.drop()\n",
    "multasJ20 = spark.read.csv('Multas/202006_detalle.csv', header=True, inferSchema=True, sep=\";\").na.drop()\n",
    "multasJu20 = spark.read.csv('Multas/202007_detalle.csv', header=True, inferSchema=True, sep=\";\").na.drop()\n",
    "\n",
    "unionFase2 = multasA20.union(multasMa20).union(multasJ20).union(multasJu20)\n",
    "intFase2 = unionFase2.withColumn(\"Fases\", lit('Primer estado'))\n",
    "\n",
    "intFase2 = intFase2.groupBy(\"Fases\").count()\n",
    "intFase2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+\n",
      "|           Fases| count|\n",
      "+----------------+------+\n",
      "|Nueva normalidad|553510|\n",
      "+----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multasAg20 = spark.read.csv('Multas/202008_detalle.csv', header=True, inferSchema=True, sep=\";\").na.drop()\n",
    "multasS20 = spark.read.csv('Multas/202009_detalle.csv', header=True, inferSchema=True, sep=\";\").na.drop()\n",
    "multasO20 = spark.read.csv('Multas/202010_detalle.csv', header=True, inferSchema=True, sep=\";\").na.drop()\n",
    "\n",
    "unionFase3 = multasAg20.union(multasS20).union(multasO20)\n",
    "intFase3 = unionFase3.withColumn(\"Fases\", lit('Nueva normalidad'))\n",
    "\n",
    "intFase3 = intFase3.groupBy(\"Fases\").count()\n",
    "intFase3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------+\n",
      "|         Fases|  count|\n",
      "+--------------+-------+\n",
      "|Segundo estado|1310436|\n",
      "+--------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multasN20 = spark.read.csv('Multas/202011_detalle.csv', header=True, inferSchema=True, sep=\";\").na.drop()\n",
    "multasD20 = spark.read.csv('Multas/202012_detalle.csv', header=True, inferSchema=True, sep=\";\").na.drop()\n",
    "multasE21 = spark.read.csv('Multas/202101_detalle.csv', header=True, inferSchema=True, sep=\";\").na.drop()\n",
    "multasF21 = spark.read.csv('Multas/202102_detalle.csv', header=True, inferSchema=True, sep=\";\").na.drop()\n",
    "multasM21 = spark.read.csv('Multas/202103_detalle.csv', header=True, inferSchema=True, sep=\";\").na.drop()\n",
    "multasA21 = spark.read.csv('Multas/202104_detalle.csv', header=True, inferSchema=True, sep=\";\").na.drop()\n",
    "multasMa21 = spark.read.csv('Multas/202105_detalle.csv', header=True, inferSchema=True, sep=\";\").na.drop()\n",
    "\n",
    "\n",
    "unionFase4 = multasN20.union(multasD20).union(multasE21).union(multasF21).union(multasM21).union(multasA21).union(multasMa21)\n",
    "intFase4 = unionFase4.withColumn(\"Fases\", lit('Segundo estado'))\n",
    "\n",
    "intFase4 = intFase4.groupBy(\"Fases\").count()\n",
    "intFase4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+\n",
      "|             Fases|  count|\n",
      "+------------------+-------+\n",
      "|Pos-segundo estado|1093701|\n",
      "+------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multasJ21 = spark.read.csv('Multas/202106_detalle.csv', header=True, inferSchema=True, sep=\";\").na.drop()\n",
    "multasJu21 = spark.read.csv('Multas/202107_detalle.csv', header=True, inferSchema=True, sep=\";\").na.drop()\n",
    "multasAg21 = spark.read.csv('Multas/202108_detalle.csv', header=True, inferSchema=True, sep=\";\").na.drop()\n",
    "multasS21 = spark.read.csv('Multas/202109_detalle.csv', header=True, inferSchema=True, sep=\";\").na.drop()\n",
    "multasO21 = spark.read.csv('Multas/202110_detalle.csv', header=True, inferSchema=True, sep=\";\").na.drop()\n",
    "multasN21 = spark.read.csv('Multas/202111_detalle.csv', header=True, inferSchema=True, sep=\";\").na.drop()\n",
    "multasD21 = spark.read.csv('Multas/202112_detalle.csv', header=True, inferSchema=True, sep=\";\").na.drop()\n",
    "\n",
    "unionFase5 = multasJ21.union(multasJu21).union(multasAg21).union(multasS21).union(multasO21).union(multasN21).union(multasD21)\n",
    "intFase5 = unionFase5.withColumn(\"Fases\", lit('Pos-segundo estado'))\n",
    "intFase5 = intFase5.groupBy(\"Fases\").count()\n",
    "intFase5.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Fases  Cantidad de multas\n",
      "0        Pre Covid-19              804063\n",
      "1       Primer estado              487713\n",
      "2    Nueva normalidad              553510\n",
      "3      Segundo estado             1310436\n",
      "4  Pos-segundo estado             1093701\n"
     ]
    }
   ],
   "source": [
    "unionFinal = intFase1.union(intFase2).union(intFase3).union(intFase4).union(intFase5)\n",
    "nombre = unionFinal.withColumnRenamed(\"count\", \"Cantidad de multas\")\n",
    "union = nombre.toPandas()\n",
    "print(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union.to_csv(\"resultadoMultas.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c8ea1c5ea903086be3ae2f54f30b4d1188bc743928b3c99b4e8bf5ea7010a784"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
